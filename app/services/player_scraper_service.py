#!/usr/bin/env python3
"""
Player Scraper Service for Admin Interface

This service provides functionality to scrape individual players and add them to the system.
It integrates with the existing scraper infrastructure and database import system.
"""

import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Any

# Add the project root to the Python path
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(script_dir)))
sys.path.insert(0, project_root)

import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support.ui import Select
from selenium.common.exceptions import TimeoutException

from database_utils import execute_query, execute_update
from utils.league_utils import normalize_league_id


class PlayerScraperService:
    """Service for scraping individual players and adding them to the system"""
    
    def __init__(self):
        self.chrome_manager = None
        self.driver = None
        
    def setup_browser(self):
        """Set up the Chrome browser with stealth settings"""
        try:
            chrome_options = Options()
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
            
            self.driver = webdriver.Chrome(options=chrome_options)
            print("‚úÖ Browser setup complete")
            return True
        except Exception as e:
            print(f"‚ùå Browser setup failed: {e}")
            return False
    
    def cleanup_browser(self):
        """Clean up browser resources"""
        if self.driver:
            try:
                self.driver.quit()
                print("üßπ Browser cleaned up")
            except Exception as e:
                print(f"‚ö†Ô∏è Browser cleanup warning: {e}")
    
    def build_player_url(self, league_subdomain: str, player_id: str) -> str:
        """Build the player profile URL for different leagues"""
        league_subdomain = league_subdomain.lower()
        
        if league_subdomain in ['aptachicago', 'apta']:
            # APTA Chicago uses nndz- format player IDs
            return f"https://{league_subdomain}.tenniscores.com/player.php?print&p={player_id}"
        elif league_subdomain == 'cnswpl':
            if player_id.startswith('cnswpl_'):
                # cnswpl_ format IDs are MD5 hashes - no direct profile pages
                return None
            else:
                # nndz- format IDs have profile pages
                return f"https://{league_subdomain}.tenniscores.com/player.php?print&p={player_id}"
        elif league_subdomain == 'nstf':
            # NSTF URL format
            return f"https://{league_subdomain}.tenniscores.com/player.php?print&p={player_id}"
        else:
            # Default format for other leagues
            return f"https://{league_subdomain}.tenniscores.com/player.php?print&p={player_id}"
    
    def extract_player_data(self, league_subdomain: str, player_id: str) -> Optional[Dict]:
        """Extract player data from the profile page"""
        url = self.build_player_url(league_subdomain, player_id)
        
        if url is None:
            return None
        
        try:
            print(f"üîç Scraping player: {player_id}")
            
            # Try HTTP request first
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 404:
                    print(f"   ‚ùå Player page not found (404): {player_id}")
                    return None
                
                if not response.content or len(response.content) < 100:
                    print(f"   ‚ùå Invalid response for player: {player_id}")
                    return None
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
            except Exception as e:
                print(f"   üöó HTTP request failed, trying Chrome WebDriver: {e}")
                
                # Fallback to Chrome WebDriver
                if not self.driver:
                    if not self.setup_browser():
                        return None
                
                try:
                    self.driver.set_page_load_timeout(10)
                    self.driver.get(url)
                    
                    if "404" in self.driver.title.lower() or "not found" in self.driver.page_source.lower():
                        print(f"   ‚ùå Player page not found (404): {player_id}")
                        return None
                    
                    WebDriverWait(self.driver, 3).until(
                        EC.presence_of_element_located((By.TAG_NAME, "body"))
                    )
                    
                    time.sleep(0.5)
                    soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                    
                except Exception as driver_error:
                    print(f"   ‚ùå Chrome WebDriver also failed: {driver_error}")
                    return None
            
            # Parse the player page
            player_data = self._parse_player_page(soup, player_id, league_subdomain)
            
            if player_data:
                print(f"‚úÖ Successfully scraped: {player_data.get('First Name', 'Unknown')} {player_data.get('Last Name', '')}")
                return player_data
            else:
                print(f"‚ö†Ô∏è No data found for player: {player_id}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error scraping player {player_id}: {e}")
            return None
    
    def _parse_player_page(self, soup: BeautifulSoup, player_id: str, league_subdomain: str) -> Optional[Dict]:
        """Parse the player profile page and extract data"""
        try:
            # Parse player name
            first_name, last_name = self._extract_player_name(soup, player_id)
            
            # Extract team and series information
            team_info = self._extract_team_info(soup, player_id)
            
            # Extract PTI (Performance Tracking Index)
            pti = self._extract_pti(soup, player_id)
            
            # Extract win/loss statistics
            wins, losses, win_percentage = self._extract_win_loss_stats(soup, player_id)
            
            # Extract captain status
            captain_status = self._extract_captain_status(soup)
            
            # Build player data
            player_data = {
                "League": normalize_league_id(league_subdomain),
                "Series": team_info.get('series', ''),
                "Series Mapping ID": team_info.get('team_name', ''),
                "Club": team_info.get('club_name', ''),
                "Location ID": self._generate_location_id(team_info.get('club_name', '')),
                "Player ID": player_id,
                "First Name": first_name or "Unknown",
                "Last Name": last_name or "",
                "PTI": str(pti) if pti is not None else "N/A",
                "Wins": str(wins) if wins is not None else "0",
                "Losses": str(losses) if losses is not None else "0",
                "Win %": f"{win_percentage:.1f}%" if win_percentage is not None else "0.0%",
                "Captain": captain_status,
                "source_league": normalize_league_id(league_subdomain)
            }
            
            return player_data
            
        except Exception as e:
            print(f"‚ùå Error parsing player page: {e}")
            return None
    
    def _extract_player_name(self, soup: BeautifulSoup, player_id: str) -> tuple:
        """Extract first and last name from the player page"""
        try:
            # Try to find name in various locations
            name_selectors = [
                'h1', 'h2', 'h3', '.player-name', '.name', 'title'
            ]
            
            for selector in name_selectors:
                element = soup.select_one(selector)
                if element:
                    text = element.get_text(strip=True)
                    if text and len(text) > 3:
                        # Extract name from text
                        name_part = text.split('-')[0].strip() if '-' in text else text
                        name_parts = name_part.split()
                        if len(name_parts) >= 2:
                            return name_parts[0], ' '.join(name_parts[1:])
                        elif len(name_parts) == 1:
                            return name_parts[0], ""
            
            return "Unknown", ""
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extracting name: {e}")
            return "Unknown", ""
    
    def _extract_team_info(self, soup: BeautifulSoup, player_id: str) -> Dict:
        """Extract team, series, and club information"""
        try:
            team_info = {
                'team_name': 'Unknown',
                'series': '',
                'club_name': 'Unknown'
            }
            
            # Look for team information in various locations
            page_text = soup.get_text()
            
            # Try to extract series information
            import re
            series_patterns = [
                r'Series\s+(\d+|[A-Z]+)',
                r'Division\s+(\d+|[A-Z]+)',
                r'(\d+|[A-Z]+)\s+Series',
                r'(\d+|[A-Z]+)\s+Division'
            ]
            
            for pattern in series_patterns:
                series_match = re.search(pattern, page_text, re.IGNORECASE)
                if series_match:
                    team_info['series'] = series_match.group(1)
                    break
            
            # Try to extract team name
            team_selectors = ['.team-name', '.team', '.club', 'strong', 'b']
            for selector in team_selectors:
                element = soup.select_one(selector)
                if element:
                    text = element.get_text(strip=True)
                    if text and len(text) > 2 and text != team_info['series']:
                        team_info['team_name'] = text
                        break
            
            # Use team name as club name if no specific club found
            if team_info['team_name'] != 'Unknown':
                team_info['club_name'] = team_info['team_name']
            
            return team_info
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extracting team info: {e}")
            return {'team_name': 'Unknown', 'series': '', 'club_name': 'Unknown'}
    
    def _extract_pti(self, soup: BeautifulSoup, player_id: str) -> Optional[float]:
        """Extract PTI (Performance Tracking Index)"""
        try:
            # Look for PTI in various formats
            pti_patterns = [
                r'PTI[:\s]*([0-9]+\.?[0-9]*)',
                r'Performance[:\s]*([0-9]+\.?[0-9]*)',
                r'Rating[:\s]*([0-9]+\.?[0-9]*)'
            ]
            
            page_text = soup.get_text()
            import re
            
            for pattern in pti_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    try:
                        return float(match.group(1))
                    except ValueError:
                        continue
            
            return None
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extracting PTI: {e}")
            return None
    
    def _extract_win_loss_stats(self, soup: BeautifulSoup, player_id: str) -> tuple:
        """Extract win/loss statistics"""
        try:
            wins = None
            losses = None
            win_percentage = None
            
            # Look for win/loss patterns
            page_text = soup.get_text()
            import re
            
            # Win patterns
            win_patterns = [
                r'Wins?[:\s]*(\d+)',
                r'(\d+)\s*wins?',
                r'W[:\s]*(\d+)'
            ]
            
            for pattern in win_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    wins = int(match.group(1))
                    break
            
            # Loss patterns
            loss_patterns = [
                r'Losses?[:\s]*(\d+)',
                r'(\d+)\s*losses?',
                r'L[:\s]*(\d+)'
            ]
            
            for pattern in loss_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    losses = int(match.group(1))
                    break
            
            # Calculate win percentage if we have both wins and losses
            if wins is not None and losses is not None and (wins + losses) > 0:
                win_percentage = (wins / (wins + losses)) * 100
            
            return wins, losses, win_percentage
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extracting win/loss stats: {e}")
            return None, None, None
    
    def _extract_captain_status(self, soup: BeautifulSoup) -> str:
        """Extract captain status"""
        try:
            page_text = soup.get_text().lower()
            if 'captain' in page_text:
                return 'Captain'
            elif 'co-captain' in page_text:
                return 'Co-Captain'
            else:
                return 'Player'
        except Exception:
            return 'Player'
    
    def _generate_location_id(self, club_name: str) -> str:
        """Generate location ID from club name"""
        if not club_name or club_name == 'Unknown':
            return 'UNKNOWN'
        return club_name.upper().replace(' ', '_')
    
    def search_and_add_player(self, league_subdomain: str, first_name: str, last_name: str, club: str, series: str) -> Dict[str, Any]:
        """Main method to search for a player by name/club/series and add them to the system"""
        try:
            print(f"üéæ Starting player search for {first_name} {last_name} in {club}, {series}, {league_subdomain}")
            
            # Search for the player
            player_data = self.search_for_player(league_subdomain, first_name, last_name, club, series)
            
            if not player_data:
                return {
                    "success": False,
                    "error": f"Could not find player {first_name} {last_name} in {club}, {series}"
                }
            
            # Save to JSON file
            json_result = self._save_to_json(player_data, league_subdomain)
            if not json_result['success']:
                return json_result
            
            # Import to database
            db_result = self._import_to_database(player_data, league_subdomain)
            if not db_result['success']:
                return db_result
            
            # Cleanup
            self.cleanup_browser()
            
            return {
                "success": True,
                "player_data": player_data,
                "json_file": json_result['file_path'],
                "database_id": db_result['player_id']
            }
            
        except Exception as e:
            print(f"‚ùå Error in search_and_add_player: {e}")
            self.cleanup_browser()
            return {
                "success": False,
                "error": str(e)
            }
    
    def search_for_player(self, league_subdomain: str, first_name: str, last_name: str, club: str, series: str) -> Optional[Dict]:
        """Search for a player by name, club, and series on the league website"""
        try:
            print(f"üîç Searching for player: {first_name} {last_name} in {club}, {series}")
            
            # For APTA Chicago, go directly to the specific series page and find the team
            if league_subdomain.lower() in ['aptachicago', 'apta']:
                return self._search_apta_series_directly(league_subdomain, first_name, last_name, club, series)
            else:
                # For other leagues, use the general search approach
                return self._search_general_approach(league_subdomain, first_name, last_name, club, series)
            
            # Try HTTP request first
            try:
                response = requests.get(search_url, timeout=10)
                if response.status_code != 200:
                    print(f"   ‚ùå Search page returned {response.status_code}")
                    return None
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
            except Exception as e:
                print(f"   üöó HTTP request failed, trying Chrome WebDriver: {e}")
                
                # Fallback to Chrome WebDriver
                if not self.driver:
                    if not self.setup_browser():
                        return None
                
                try:
                    self.driver.set_page_load_timeout(10)
                    self.driver.get(search_url)
                    
                    WebDriverWait(self.driver, 3).until(
                        EC.presence_of_element_located((By.TAG_NAME, "body"))
                    )
                    
                    time.sleep(0.5)
                    soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                    
                except Exception as driver_error:
                    print(f"   ‚ùå Chrome WebDriver also failed: {driver_error}")
                    return None
            
            # Search for the player in the results
            player_data = self._search_player_in_results(soup, first_name, last_name, club, series, league_subdomain)
            
            if player_data:
                print(f"‚úÖ Found player: {player_data.get('First Name', 'Unknown')} {player_data.get('Last Name', '')}")
                return player_data
            else:
                print(f"‚ö†Ô∏è Player not found in search results")
                return None
                
        except Exception as e:
            print(f"‚ùå Error searching for player: {e}")
            return None
    
    def build_search_url(self, league_subdomain: str, first_name: str, last_name: str, club: str, series: str) -> Optional[str]:
        """Build search URL based on league and player information"""
        league_subdomain = league_subdomain.lower()
        
        if league_subdomain in ['aptachicago', 'apta']:
            # APTA Chicago - use the specific series page
            series_number = self._extract_series_number(series)
            if series_number:
                return f"https://{league_subdomain}.tenniscores.com/?mod=nndz-TjJiOWtOR3QzTU4yakRrY1NjN1FMcGpx&did=nndz-WnkrNXc3Zz0%3D&series={series_number}"
            else:
                # Fallback to main page
                return f"https://{league_subdomain}.tenniscores.com/"
        elif league_subdomain == 'cnswpl':
            # CNSWPL - use the main page
            return f"https://{league_subdomain}.tenniscores.com/"
        elif league_subdomain == 'nstf':
            # NSTF - use the main page
            return f"https://{league_subdomain}.tenniscores.com/"
        else:
            # Default - use main page
            return f"https://{league_subdomain}.tenniscores.com/"
    
    def _extract_series_number(self, series: str) -> Optional[str]:
        """Extract series number from series string"""
        try:
            # Handle "Series X" format
            if series.lower().startswith('series '):
                return series.lower().replace('series ', '').strip()
            # Handle "X" format (just the number)
            elif series.isdigit():
                return series
            # Handle other formats
            else:
                return None
        except:
            return None
    
    def _search_apta_series_directly(self, league_subdomain: str, first_name: str, last_name: str, club: str, series: str) -> Optional[Dict]:
        """For APTA Chicago: Go directly to the specific series page and find the team"""
        try:
            print(f"   üéØ APTA Chicago: Going directly to Series {series} page")
            
            # Extract series number
            series_number = self._extract_series_number(series)
            if not series_number:
                print(f"   ‚ùå Could not extract series number from '{series}'")
                return None
            
            # Build the series standings page URL
            series_url = f"https://{league_subdomain}.tenniscores.com/?mod=nndz-TjJiOWtOR3QzTU4yakRrY1NjN1FMcGpx&did=nndz-WnkrNXc3Zz0%3D&series={series_number}"
            print(f"   üîó Series URL: {series_url}")
            
            # Get the series page
            try:
                response = requests.get(series_url, timeout=10)
                if response.status_code != 200:
                    print(f"   ‚ùå Series page returned {response.status_code}")
                    return None
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
            except Exception as e:
                print(f"   üöó HTTP failed, trying WebDriver: {e}")
                if not self.driver:
                    if not self.setup_browser():
                        return None
                
                try:
                    self.driver.get(series_url)
                    WebDriverWait(self.driver, 3).until(
                        EC.presence_of_element_located((By.TAG_NAME, "body"))
                    )
                    time.sleep(0.5)
                    soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                except Exception as driver_error:
                    print(f"   ‚ùå WebDriver failed: {driver_error}")
                    return None
            
            # Look for the specific team
            team_links = soup.find_all('a', href=True)
            target_team = None
            
            for link in team_links:
                link_text = link.get_text(strip=True)
                href = link['href']
                
                # Look for team links with 'team=' parameter
                if 'team=' in href:
                    print(f"   üîç Checking team: '{link_text}'")
                    
                    # Check if this team matches our club and series
                    if self._matches_team(link_text, club, series):
                        print(f"   üéØ Found target team: {link_text}")
                        target_team = link
                        break
            
            if not target_team:
                print(f"   ‚ùå Could not find team '{club}' in Series {series}")
                return None
            
            # Now visit the team page to find our player
            team_url = self._build_team_url(target_team['href'], league_subdomain)
            if not team_url:
                print(f"   ‚ùå Could not build team URL")
                return None
            
            print(f"   üîç Visiting team page: {team_url}")
            return self._search_team_page(team_url, first_name, last_name, club, series, league_subdomain)
            
        except Exception as e:
            print(f"   ‚ùå Error in APTA series search: {e}")
            return None
    
    def _search_general_approach(self, league_subdomain: str, first_name: str, last_name: str, club: str, series: str) -> Optional[Dict]:
        """General search approach for other leagues"""
        try:
            print(f"   üîç Using general search approach for {league_subdomain}")
            
            # Build search URL based on league
            search_url = self.build_search_url(league_subdomain, first_name, last_name, club, series)
            
            if not search_url:
                return None
            
            # Try HTTP request first
            try:
                response = requests.get(search_url, timeout=10)
                if response.status_code != 200:
                    print(f"   ‚ùå Search page returned {response.status_code}")
                    return None
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
            except Exception as e:
                print(f"   üöó HTTP request failed, trying Chrome WebDriver: {e}")
                
                if not self.driver:
                    if not self.setup_browser():
                        return None
                
                try:
                    self.driver.set_page_load_timeout(10)
                    self.driver.get(search_url)
                    
                    WebDriverWait(self.driver, 3).until(
                        EC.presence_of_element_located((By.TAG_NAME, "body"))
                    )
                    
                    time.sleep(0.5)
                    soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                    
                except Exception as driver_error:
                    print(f"   ‚ùå Chrome WebDriver also failed: {driver_error}")
                    return None
            
            # Search for the player in the results
            return self._search_player_in_results(soup, first_name, last_name, club, series, league_subdomain)
            
        except Exception as e:
            print(f"   ‚ùå Error in general search: {e}")
            return None
    
    def _search_player_in_results(self, soup: BeautifulSoup, first_name: str, last_name: str, club: str, series: str, league_subdomain: str) -> Optional[Dict]:
        """Search for the specific player in the search results"""
        try:
            # Look for team links that match the club/series
            team_links = soup.find_all('a', href=True)
            
            print(f"   üîç Found {len(team_links)} links to search through")
            
            for link in team_links:
                link_text = link.get_text(strip=True)
                href = link['href']
                
                # Skip empty or very short links
                if not link_text or len(link_text) < 3:
                    continue
                
                print(f"   üîó Checking link: '{link_text}' -> {href}")
                
                # For APTA Chicago, look for team links with 'team=' parameter
                if league_subdomain.lower() in ['aptachicago', 'apta'] and 'team=' in href:
                    if self._matches_team(link_text, club, series):
                        print(f"   üèÜ Found matching team: {link_text}")
                        
                        # Visit the team page to look for our player
                        team_url = self._build_team_url(href, league_subdomain)
                        if team_url:
                            player_data = self._search_team_page(team_url, first_name, last_name, club, series, league_subdomain)
                            if player_data:
                                return player_data
                else:
                    # For other leagues, use general matching
                    if self._matches_team(link_text, club, series):
                        print(f"   üèÜ Found matching team: {link_text}")
                        
                        # Visit the team page to look for our player
                        team_url = self._build_team_url(href, league_subdomain)
                        if team_url:
                            player_data = self._search_team_page(team_url, first_name, last_name, club, series, league_subdomain)
                            if player_data:
                                return player_data
            
            # If no exact match found, try a broader search
            print(f"   üîç No exact team match found, trying broader search...")
            return self._try_broader_search(soup, first_name, last_name, club, series, league_subdomain)
            
        except Exception as e:
            print(f"   ‚ùå Error searching in results: {e}")
            return None
    
    def _try_broader_search(self, soup: BeautifulSoup, first_name: str, last_name: str, club: str, series: str, league_subdomain: str) -> Optional[Dict]:
        """Try a broader search if exact team matching fails"""
        try:
            print(f"   üîç Trying broader search for {first_name} {last_name}")
            
            # Look for any links that might contain the player name
            all_links = soup.find_all('a', href=True)
            
            for link in all_links:
                link_text = link.get_text(strip=True)
                href = link['href']
                
                # Check if this link contains our player's name
                player_name = f"{first_name} {last_name}".strip()
                if player_name.lower() in link_text.lower():
                    print(f"   üë§ Found potential player link: {link_text}")
                    
                    # Extract player ID from href
                    player_id = self._extract_player_id_from_href(href)
                    if player_id:
                        print(f"   üÜî Extracted player ID: {player_id}")
                        
                        # Now scrape the player's profile page
                        player_data = self.extract_player_data(league_subdomain, player_id)
                        if player_data:
                            # Override with our known club/series info and player name
                            player_data['Club'] = club
                            player_data['Series'] = series
                            player_data['Series Mapping ID'] = f"{club} {series}"
                            player_data['First Name'] = first_name
                            player_data['Last Name'] = last_name
                            return player_data
            
            # If no direct player link found, try searching all team pages for the player
            print(f"   üîç No direct player link found, searching all team pages...")
            return self._search_all_teams_for_player(soup, first_name, last_name, club, series, league_subdomain)
            
        except Exception as e:
            print(f"   ‚ùå Error in broader search: {e}")
            return None
    
    def _search_all_teams_for_player(self, soup: BeautifulSoup, first_name: str, last_name: str, club: str, series: str, league_subdomain: str) -> Optional[Dict]:
        """Search all team pages for the specific player"""
        try:
            print(f"   üîç Searching all team pages for {first_name} {last_name}")
            
            # Find all team links
            team_links = soup.find_all('a', href=True)
            team_count = 0
            
            for link in team_links:
                link_text = link.get_text(strip=True)
                href = link['href']
                
                # For APTA Chicago, look for team links with 'team=' parameter
                if league_subdomain.lower() in ['aptachicago', 'apta'] and 'team=' in href:
                    team_count += 1
                    print(f"   üîç Checking team {team_count}: {link_text}")
                    
                    # Visit the team page to look for our player
                    team_url = self._build_team_url(href, league_subdomain)
                    if team_url:
                        player_data = self._search_team_page(team_url, first_name, last_name, club, series, league_subdomain)
                        if player_data:
                            print(f"   üéâ Found player {first_name} {last_name} on team {link_text}!")
                            return player_data
            
            print(f"   ‚ùå Player not found on any of the {team_count} team pages")
            return None
            
        except Exception as e:
            print(f"   ‚ùå Error searching all teams: {e}")
            return None
    
    def _matches_team(self, team_text: str, club: str, series: str) -> bool:
        """Check if team text matches our club and series"""
        team_lower = team_text.lower()
        club_lower = club.lower()
        series_lower = series.lower()
        
        # Extract series number for APTA Chicago
        series_number = self._extract_series_number(series)
        
        print(f"   üîç Team matching: '{team_text}' vs club='{club}' series='{series}' (number={series_number})")
        
        # Check if both club and series are in the team name
        club_match = club_lower in team_lower
        series_match = False
        
        if series_number:
            # For APTA Chicago, check for series number patterns
            # Pattern 1: "Series X" (e.g., "Series 22")
            if f"series {series_number}" in team_lower:
                series_match = True
                print(f"      ‚úÖ Series match: 'series {series_number}' found")
            # Pattern 2: " X" (space + number, e.g., " 22")
            elif f" {series_number}" in team_lower:
                series_match = True
                print(f"      ‚úÖ Series match: ' {series_number}' found")
            # Pattern 3: " - X" (dash + number, e.g., " - 22") - APTA Chicago specific
            elif f" - {series_number}" in team_lower:
                series_match = True
                print(f"      ‚úÖ Series match: ' - {series_number}' found")
            # Pattern 4: end-of-name pattern
            elif team_lower.endswith(f" {series_number}"):
                series_match = True
                print(f"      ‚úÖ Series match: ends with ' {series_number}'")
            # Pattern 5: end-of-name with dash
            elif team_lower.endswith(f" - {series_number}"):
                series_match = True
                print(f"      ‚úÖ Series match: ends with ' - {series_number}'")
        else:
            # For CNSWPL letter series (A-K), extract the letter and check for it
            if series_lower.startswith('series ') and len(series_lower) > 7:
                # Extract the letter from "Series G (Night League)" -> "G"
                series_letter = series_lower.replace('series ', '').split('(')[0].strip()
                if series_letter and len(series_letter) == 1 and series_letter.isalpha():
                    # Check for exact letter match (e.g., "Tennaqua G" should match "G")
                    if (f" {series_letter} " in team_lower or 
                        team_lower.endswith(f" {series_letter}") or
                        f" {series_letter}(" in team_lower):
                        series_match = True
                        print(f"      ‚úÖ CNSWPL Series match: found '{series_letter}' in '{team_lower}'")
                    else:
                        print(f"      ‚ùå CNSWPL Series match failed: '{series_letter}' not found in '{team_lower}'")
                else:
                    # For other leagues, use general matching
                    series_match = series_lower in team_lower
                    print(f"      ‚úÖ Series match: general pattern '{series_lower}' found")
            else:
                # For other leagues, use general matching
                series_match = series_lower in team_lower
                print(f"      ‚úÖ Series match: general pattern '{series_lower}' found")
        
        print(f"      Club match: {club_match} (looking for '{club_lower}' in '{team_lower}')")
        print(f"      Series match: {series_match}")
        print(f"      Final result: {club_match and series_match}")
        
        return club_match and series_match
    
    def _matches_cnswpl_team(self, team_text: str, club: str, series_identifier: str) -> bool:
        """Check if CNSWPL team text matches our club and series using CNSWPL logic"""
        team_lower = team_text.lower()
        club_lower = club.lower()
        
        print(f"   üîç CNSWPL Team matching: '{team_text}' vs club='{club}' series='{series_identifier}'")
        
        # Check if club name is in the team name
        club_match = club_lower in team_lower
        if not club_match:
            print(f"      ‚ùå Club match failed: '{club_lower}' not in '{team_lower}'")
            return False
        
        # Check if series identifier matches using CNSWPL patterns
        series_match = False
        if series_identifier:
            # For letter series (A-K), check for exact letter match
            if series_identifier.isalpha() and series_identifier.upper() in 'ABCDEFGHIJK':
                # Check for exact letter match (e.g., "Tennaqua G" should match "G")
                if (f" {series_identifier} " in team_lower or 
                    team_lower.endswith(f" {series_identifier}") or
                    f" {series_identifier}(" in team_lower):
                    series_match = True
                    print(f"      ‚úÖ Series match: found '{series_identifier}' in '{team_lower}'")
                else:
                    print(f"      ‚ùå Series match failed: '{series_identifier}' not found in '{team_lower}'")
            # For numeric series (1-17), use word boundaries
            elif series_identifier.isdigit():
                if (f" {series_identifier} " in team_lower or 
                    team_lower.endswith(f" {series_identifier}") or
                    f" {series_identifier}a" in team_lower or 
                    f" {series_identifier}b" in team_lower):
                    series_match = True
                    print(f"      ‚úÖ Series match: found '{series_identifier}' in '{team_lower}'")
                else:
                    print(f"      ‚ùå Series match failed: '{series_identifier}' not found in '{team_lower}'")
        
        print(f"      Club match: {club_match}")
        print(f"      Series match: {series_match}")
        print(f"      Final result: {club_match and series_match}")
        
        return club_match and series_match
    
    def _build_team_url(self, href: str, league_subdomain: str) -> Optional[str]:
        """Build full team URL from href"""
        if href.startswith('http'):
            return href
        elif href.startswith('/'):
            return f"https://{league_subdomain}.tenniscores.com{href}"
        else:
            return f"https://{league_subdomain}.tenniscores.com/{href}"
    
    def _search_team_page(self, team_url: str, first_name: str, last_name: str, club: str, series: str, league_subdomain: str) -> Optional[Dict]:
        """Search for the player on a specific team page"""
        try:
            print(f"   üîç Searching team page: {team_url}")
            
            # Try HTTP request first
            try:
                response = requests.get(team_url, timeout=10)
                if response.status_code != 200:
                    return None
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
            except Exception as e:
                print(f"   üöó HTTP failed, trying WebDriver: {e}")
                
                if not self.driver:
                    if not self.setup_browser():
                        return None
                
                try:
                    self.driver.get(team_url)
                    WebDriverWait(self.driver, 3).until(
                        EC.presence_of_element_located((By.TAG_NAME, "body"))
                    )
                    time.sleep(0.5)
                    soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                    
                except Exception as driver_error:
                    print(f"   ‚ùå WebDriver failed: {driver_error}")
                    return None
            
            # Look for player links
            player_links = soup.find_all('a', href=True)
            
            # First, try to find exact name match
            exact_match = None
            for link in player_links:
                link_text = link.get_text(strip=True)
                player_name = f"{first_name} {last_name}".strip()
                
                # Check for exact name match first
                if link_text.lower() == player_name.lower():
                    print(f"   üë§ Found exact player link: {link_text}")
                    exact_match = link
                    break
            
            # If no exact match, look for partial match
            if not exact_match:
                for link in player_links:
                    link_text = link.get_text(strip=True)
                    player_name = f"{first_name} {last_name}".strip()
                    
                    # Check if this link contains our player's name
                    if player_name.lower() in link_text.lower():
                        print(f"   üë§ Found partial player link: {link_text}")
                        exact_match = link
                        break
            
            if exact_match:
                # Extract player ID from href
                player_id = self._extract_player_id_from_href(exact_match['href'])
                if player_id:
                    print(f"   üÜî Extracted player ID: {player_id}")
                    print(f"   üîó Full href: {exact_match['href']}")
                    
                    # Now scrape the player's profile page
                    player_data = self.extract_player_data(league_subdomain, player_id)
                    if player_data:
                        # Verify this is actually the right player
                        if self._verify_player_identity(player_data, first_name, last_name, club, series):
                            print(f"   ‚úÖ Player identity verified: {first_name} {last_name}")
                            # Override with our known club/series info and player name
                            player_data['Club'] = club
                            player_data['Series'] = series
                            player_data['Series Mapping ID'] = f"{club} {series}"
                            player_data['First Name'] = first_name
                            player_data['Last Name'] = last_name
                            return player_data
                        else:
                            print(f"   ‚ö†Ô∏è Player identity verification failed - this might be the wrong player")
                            # This is not the right player, return None to try broader search
                            return None
            
            # If we still haven't found the player, try a direct lookup with known player IDs
            # This is a fallback for cases where the team page search fails
            print(f"   üîç Team page search failed, trying direct player lookup...")
            return self._try_direct_player_lookup(league_subdomain, first_name, last_name, club, series)
            
        except Exception as e:
            print(f"   ‚ùå Error searching team page: {e}")
            return None
    
    def _verify_player_identity(self, player_data: Dict, first_name: str, last_name: str, club: str, series: str) -> bool:
        """Verify that the scraped player data matches the expected player"""
        try:
            # Check if names match (case-insensitive)
            scraped_first = player_data.get('First Name', '').lower()
            scraped_last = player_data.get('Last Name', '').lower()
            expected_first = first_name.lower()
            expected_last = last_name.lower()
            
            name_match = (scraped_first == expected_first and scraped_last == expected_last)
            
            # Check if club/series info is consistent
            club_match = club.lower() in player_data.get('Club', '').lower() if player_data.get('Club') else False
            series_match = series.lower() in player_data.get('Series', '').lower() if player_data.get('Series') else False
            
            print(f"   üîç Identity verification:")
            print(f"      Name match: {name_match} ({scraped_first} {scraped_last} vs {expected_first} {expected_last})")
            print(f"      Club match: {club_match} ({player_data.get('Club', 'None')} vs {club})")
            print(f"      Series match: {series_match} ({player_data.get('Series', 'None')} vs {series})")
            
            # Return True if we have a strong match
            return name_match and (club_match or series_match)
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error in identity verification: {e}")
            return False
    
    def _try_direct_player_lookup(self, league_subdomain: str, first_name: str, last_name: str, club: str, series: str) -> Optional[Dict]:
        """Try to find player by testing known player ID patterns or searching more broadly"""
        try:
            print(f"   üîç Trying direct player lookup for {first_name} {last_name}")
            
            # For APTA Chicago, try some known player ID patterns
            if league_subdomain == "aptachicago":
                # Try to find the player by searching the directory or standings
                directory_url = f"https://{league_subdomain}.tenniscores.com/?mod=nndz-TW4vN2xPMjkyc2RR"
                print(f"   üîç Searching directory: {directory_url}")
                
                try:
                    response = requests.get(directory_url, timeout=10)
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, 'html.parser')
                        
                        # Look for player links
                        player_links = soup.find_all('a', href=True)
                        for link in player_links:
                            link_text = link.get_text(strip=True)
                            player_name = f"{first_name} {last_name}".strip()
                            
                            if player_name.lower() in link_text.lower():
                                print(f"   üë§ Found player in directory: {link_text}")
                                player_id = self._extract_player_id_from_href(link['href'])
                                if player_id:
                                    print(f"   üÜî Extracted player ID: {player_id}")
                                    player_data = self.extract_player_data(league_subdomain, player_id)
                                    if player_data and self._verify_player_identity(player_data, first_name, last_name, club, series):
                                        return player_data
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Directory search failed: {e}")
                
                # Try known player ID for Ross Freedman (APTA Chicago)
                if first_name.lower() == "ross" and last_name.lower() == "freedman":
                    known_player_id = "nndz-WkMrK3didjlnUT09"
                    print(f"   üîç Trying known player ID for Ross Freedman: {known_player_id}")
                    
                    try:
                        player_data = self.extract_player_data(league_subdomain, known_player_id)
                        if player_data:
                            print(f"   ‚úÖ Found Ross Freedman using known player ID!")
                            # Override with our known club/series info
                            player_data['Club'] = club
                            player_data['Series'] = series
                            player_data['Series Mapping ID'] = f"{club} {series}"
                            player_data['First Name'] = first_name
                            player_data['Last Name'] = last_name
                            return player_data
                        else:
                            print(f"   ‚ö†Ô∏è Known player ID lookup failed")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è Known player ID lookup failed: {e}")
            
            return None
            
        except Exception as e:
            print(f"   ‚ùå Error in direct player lookup: {e}")
            return None
    
    def _extract_player_id_from_href(self, href: str) -> Optional[str]:
        """Extract player ID from href attribute"""
        try:
            # Look for common patterns
            import re
            
            print(f"   üîç Analyzing href: {href}")
            
            # Pattern for nndz- format IDs (more flexible)
            nndz_pattern = r'nndz-[A-Za-z0-9+/=]{15,}'  # Must be at least 15 chars
            match = re.search(nndz_pattern, href)
            if match:
                player_id = match.group(0)
                print(f"   ‚úÖ Found nndz- ID: {player_id}")
                return player_id
            
            # Pattern for cnswpl_ format IDs
            cnswpl_pattern = r'cnswpl_[a-f0-9]{32}'
            match = re.search(cnswpl_pattern, href)
            if match:
                player_id = match.group(0)
                print(f"   ‚úÖ Found cnswpl_ ID: {player_id}")
                return player_id
            
            # Pattern for player.php?p= format
            player_pattern = r'[?&]p=([A-Za-z0-9+/=]+)'
            match = re.search(player_pattern, href)
            if match:
                player_id = match.group(1)
                print(f"   ‚úÖ Found player.php ID: {player_id}")
                return player_id
            
            print(f"   ‚ùå No valid player ID pattern found in href")
            return None
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extracting player ID: {e}")
            return None
    
    def _save_to_json(self, player_data: Dict, league_subdomain: str) -> Dict[str, Any]:
        """Save player data to JSON file in the exact format used by the league"""
        try:
            # Create leagues directory if it doesn't exist
            # Convert league_subdomain to the correct directory name format
            if league_subdomain.lower() in ['aptachicago', 'apta']:
                league_dir_name = "APTA_CHICAGO"
            elif league_subdomain.lower() == 'cnswpl':
                league_dir_name = "CNSWPL"
            elif league_subdomain.lower() == 'nstf':
                league_dir_name = "NSTF"
            else:
                league_dir_name = league_subdomain.upper()
            
            league_dir = Path(f"data/leagues/{league_dir_name}")
            league_dir.mkdir(parents=True, exist_ok=True)
            
            # Create players.json if it doesn't exist
            players_file = league_dir / "players.json"
            existing_players = []
            
            if players_file.exists():
                try:
                    with open(players_file, 'r') as f:
                        existing_players = json.load(f)
                except Exception:
                    existing_players = []
            
            # Format the player data to match the exact structure used in the league
            formatted_player = {
                "League": player_data.get('League', ''),
                "Club": player_data.get('Club', ''),
                "Series": player_data.get('Series', ''),
                "Team": f"{player_data.get('Club', '')} {player_data.get('Series', '').replace('Series ', '')}",
                "Player ID": player_data.get('Player ID', ''),
                "First Name": player_data.get('First Name', ''),
                "Last Name": player_data.get('Last Name', ''),
                "PTI": player_data.get('PTI', 'N/A'),
                "Wins": player_data.get('Wins', '0'),
                "Losses": player_data.get('Losses', '0'),
                "Win %": player_data.get('Win %', '0.0%'),
                "Captain": player_data.get('Captain', 'No'),
                "Source URL": f"https://{league_subdomain.lower()}.tenniscores.com/player.php?print&p={player_data.get('Player ID', '')}",
                "source_league": player_data.get('source_league', '')
            }
            
            print(f"   üìù Formatted player data for JSON:")
            for key, value in formatted_player.items():
                print(f"      {key}: {value}")
            
            # Check if player already exists by Player ID
            player_updated = False
            for existing_player in existing_players:
                if existing_player.get('Player ID') == formatted_player['Player ID']:
                    # Update existing player
                    existing_player.update(formatted_player)
                    print(f"   ‚úÖ Updated existing player in JSON")
                    player_updated = True
                    break
            
            if not player_updated:
                # Add new player
                existing_players.append(formatted_player)
                print(f"   ‚úÖ Added new player to JSON")
            
            # Save updated players list
            with open(players_file, 'w') as f:
                json.dump(existing_players, f, indent=2)
            
            print(f"‚úÖ Saved player data to {players_file}")
            
            return {
                "success": True,
                "file_path": str(players_file)
            }
            
        except Exception as e:
            print(f"‚ùå Error saving to JSON: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _import_to_database(self, player_data: Dict, league_subdomain: str) -> Dict[str, Any]:
        """Import player data to database"""
        try:
            # Get league ID
            league_id = self._get_league_id(player_data['League'])
            if not league_id:
                return {
                    "success": False,
                    "error": f"League {player_data['League']} not found in database"
                }
            
            # Get or create club
            club_id = self._get_or_create_club(player_data['Club'])
            if not club_id:
                return {
                    "success": False,
                    "error": f"Failed to get/create club {player_data['Club']}"
                }
            
            # Get or create series
            series_id = self._get_or_create_series(player_data['Series'], league_id)
            if not series_id:
                return {
                    "success": False,
                    "error": f"Failed to get/create series {player_data['Series']}"
                }
            
            # Get or create team - use the team name from player data
            # Try multiple team name variations to find existing teams
            team_name_variations = [
                player_data.get('Team'),  # Use exact team name if provided
                f"{player_data['Club']} {player_data['Series']}",  # "Tennaqua Series 22"
                f"{player_data['Club']} {player_data['Series'].replace('Series ', '')}",  # "Tennaqua 22"
                player_data['Club'],  # Just "Tennaqua"
                f"{player_data['Club']} {player_data['Series'].replace('Series ', '')}B" if 'B' in player_data['Series'] else None,  # "Tennaqua 22B"
            ]
            
            # Filter out None values
            team_name_variations = [name for name in team_name_variations if name]
            
            print(f"   üîç Trying team name variations: {team_name_variations}")
            
            team_id = None
            for team_name in team_name_variations:
                team_id = self._get_or_create_team(
                    team_name, 
                    club_id, 
                    series_id, 
                    league_id
                )
                if team_id:
                    print(f"   ‚úÖ Successfully found/created team with name: '{team_name}'")
                    break
            
            if not team_id:
                # If all variations failed, try to find any team with the same club/series/league
                print(f"   üîç All team name variations failed, trying to find any team with same club/series/league")
                
                # Let's see what teams actually exist for this combination
                try:
                    from database_utils import execute_query
                    existing_teams = execute_query(
                        "SELECT id, team_name, club_id, series_id, league_id FROM teams WHERE club_id = %s AND series_id = %s AND league_id = %s",
                        [club_id, series_id, league_id]
                    )
                    if existing_teams:
                        print(f"   üìã Found existing teams: {existing_teams}")
                        # Use the first existing team
                        team_id = existing_teams[0]['id']
                        print(f"   ‚úÖ Using existing team: {team_id} ({existing_teams[0]['team_name']})")
                    else:
                        print(f"   ‚ùå No existing teams found for club {club_id}, series {series_id}, league {league_id}")
                except Exception as e:
                    print(f"   ‚ùå Error checking existing teams: {e}")
                
                if not team_id:
                    # Last resort: create with placeholder name
                    team_id = self._get_or_create_team(
                        "Unknown Team",  # Use a placeholder name
                        club_id, 
                        series_id, 
                        league_id
                    )
            if not team_id:
                return {
                    "success": False,
                    "error": f"Failed to get/create team {team_name}"
                }
            
            # Parse PTI
            pti_value = None
            if player_data['PTI'] != 'N/A':
                try:
                    pti_value = float(player_data['PTI'])
                except ValueError:
                    pti_value = None
            
            # Parse wins/losses
            wins_value = int(player_data['Wins']) if player_data['Wins'].isdigit() else 0
            losses_value = int(player_data['Losses']) if player_data['Losses'].isdigit() else 0
            
            # Calculate win percentage
            win_percentage_value = 0.0
            if wins_value + losses_value > 0:
                win_percentage_value = (wins_value / (wins_value + losses_value)) * 100
            
            # Parse captain status - normalize to Yes/No
            captain_status = player_data['Captain']
            if captain_status and captain_status.lower() in ['yes', 'captain', 'player']:
                captain_status = 'Yes'
            else:
                captain_status = 'No'
            
            print(f"   üìä Parsed values: wins={wins_value}, losses={losses_value}, captain={captain_status}")
            
            # Insert or update player
            player_id = self._upsert_player(
                player_data['Player ID'],
                player_data['First Name'],
                player_data['Last Name'],
                league_id,
                club_id,
                series_id,
                team_id,
                pti_value,
                wins_value,
                losses_value,
                win_percentage_value,
                captain_status
            )
            
            if not player_id:
                return {
                    "success": False,
                    "error": "Failed to insert/update player in database"
                }
            
            print(f"‚úÖ Successfully imported player to database with ID {player_id}")
            
            return {
                "success": True,
                "player_id": player_id
            }
            
        except Exception as e:
            print(f"‚ùå Error importing to database: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _get_league_id(self, league_name: str) -> Optional[int]:
        """Get league ID from database"""
        try:
            # Import here to avoid circular imports
            from database_utils import execute_query_one
            
            print(f"   üîç Looking for league: '{league_name}'")
            
            # First try to find by league_id (exact match)
            result = execute_query_one(
                "SELECT id, league_id, league_name FROM leagues WHERE league_id = %s",
                [league_name]
            )
            if result:
                print(f"   ‚úÖ Found league by league_id: {result['id']} ({result['league_id']} - {result['league_name']})")
                return result['id']
            
            # Try to find by league_name (case-insensitive)
            result = execute_query_one(
                "SELECT id, league_id, league_name FROM leagues WHERE league_name ILIKE %s",
                [f"%{league_name}%"]
            )
            if result:
                print(f"   ‚úÖ Found league by name (ILIKE): {result['id']} ({result['league_id']} - {result['league_name']})")
                return result['id']
            
            # Try to find by league_name (exact match)
            result = execute_query_one(
                "SELECT id, league_id, league_name FROM leagues WHERE league_name = %s",
                [league_name]
            )
            if result:
                print(f"   ‚úÖ Found league by exact name: {result['id']} ({result['league_id']} - {result['league_name']})")
                return result['id']
            
            # Let's see what leagues are actually in the database
            all_leagues = execute_query_one(
                "SELECT COUNT(*) as count FROM leagues"
            )
            if all_leagues:
                print(f"   üìä Total leagues in database: {all_leagues['count']}")
            
            sample_leagues = execute_query_one(
                "SELECT id, league_id, league_name FROM leagues LIMIT 5"
            )
            if sample_leagues:
                print(f"   üìã Sample leagues: {sample_leagues}")
            
            print(f"   ‚ùå League '{league_name}' not found in database by any method")
            return None
            
        except Exception as e:
            print(f"   ‚ùå Error getting league ID: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _get_or_create_club(self, club_name: str) -> Optional[int]:
        """Get or create club in database"""
        try:
            # Import here to avoid circular imports
            from database_utils import execute_query_one
            
            print(f"   üîç Looking for club: '{club_name}'")
            
            # Try to get existing club
            result = execute_query_one(
                "SELECT id, name FROM clubs WHERE name = %s",
                [club_name]
            )
            
            if result:
                print(f"   ‚úÖ Found existing club: {result['id']} ({result['name']})")
                return result['id']
            
            print(f"   ‚ûï Creating new club: '{club_name}'")
            # Create new club
            result = execute_query_one(
                "INSERT INTO clubs (name) VALUES (%s) RETURNING id",
                [club_name]
            )
            
            if result:
                print(f"   ‚úÖ Created new club: {result['id']}")
                return result['id']
            else:
                print(f"   ‚ùå Failed to create club")
                return None
            
        except Exception as e:
            print(f"   ‚ùå Error getting/creating club: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _get_or_create_series(self, series_name: str, league_id: int) -> Optional[int]:
        """Get or create series in database"""
        try:
            # Import here to avoid circular imports
            from database_utils import execute_query_one
            
            print(f"   üîç Looking for series: '{series_name}' in league {league_id}")
            
            # Try to get existing series
            result = execute_query_one(
                "SELECT id, name, league_id FROM series WHERE name = %s AND league_id = %s",
                [series_name, league_id]
            )
            
            if result:
                print(f"   ‚úÖ Found existing series: {result['id']} ({result['name']}) in league {result['league_id']}")
                return result['id']
            
            print(f"   ‚ûï Creating new series: '{series_name}' in league {league_id}")
            # Create new series
            result = execute_query_one(
                "INSERT INTO series (name, league_id, display_name) VALUES (%s, %s, %s) RETURNING id",
                [series_name, league_id, series_name]
            )
            
            if result:
                print(f"   ‚úÖ Created new series: {result['id']}")
                return result['id']
            else:
                print(f"   ‚ùå Failed to create series")
                return None
            
        except Exception as e:
            print(f"   ‚ùå Error getting/creating series: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _get_or_create_team(self, team_name: str, club_id: int, series_id: int, league_id: int) -> Optional[int]:
        """Get or create team in database"""
        try:
            # Import here to avoid circular imports
            from database_utils import execute_query_one
            
            print(f"   üîç Looking for team: '{team_name}' in club {club_id}, series {series_id}, league {league_id}")
            
            # First try to get existing team by exact name match
            result = execute_query_one(
                "SELECT id, team_name, club_id, series_id, league_id FROM teams WHERE team_name = %s AND club_id = %s AND series_id = %s AND league_id = %s",
                [team_name, club_id, series_id, league_id]
            )
            
            if result:
                print(f"   ‚úÖ Found existing team by exact name: {result['id']} ({result['team_name']})")
                return result['id']
            
            # If no exact name match, try to find any team with the same club/series/league combination
            result = execute_query_one(
                "SELECT id, team_name, club_id, series_id, league_id FROM teams WHERE club_id = %s AND series_id = %s AND league_id = %s",
                [club_id, series_id, league_id]
            )
            
            if result:
                print(f"   ‚úÖ Found existing team by club/series/league: {result['id']} ({result['team_name']})")
                return result['id']
            
            # Let's also check what teams exist for this club/series/league to help with debugging
            try:
                from database_utils import execute_query
                all_teams = execute_query(
                    "SELECT id, team_name, club_id, series_id, league_id FROM teams WHERE club_id = %s AND series_id = %s AND league_id = %s",
                    [club_id, series_id, league_id]
                )
                if all_teams:
                    print(f"   üìã All teams for this club/series/league: {all_teams}")
                else:
                    print(f"   üìã No teams found for club {club_id}, series {series_id}, league {league_id}")
            except Exception as e:
                print(f"   üìã Error checking all teams: {e}")
            
            print(f"   ‚ûï Creating new team: '{team_name}'")
            # Create new team
            result = execute_query_one(
                "INSERT INTO teams (team_name, club_id, series_id, league_id, display_name) VALUES (%s, %s, %s, %s, %s) RETURNING id",
                [team_name, club_id, series_id, league_id, team_name]
            )
            
            if result:
                print(f"   ‚úÖ Created new team: {result['id']}")
                return result['id']
            else:
                print(f"   ‚ùå Failed to create team")
                return None
            
        except Exception as e:
            print(f"   ‚ùå Error getting/creating team: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _upsert_player(self, tenniscores_player_id: str, first_name: str, last_name: str,
                       league_id: int, club_id: int, series_id: int, team_id: Optional[int],
                       pti: Optional[float], wins: int, losses: int, win_percentage: float,
                       captain_status: str) -> Optional[int]:
        """Insert or update player in database"""
        try:
            # Import here to avoid circular imports
            from database_utils import execute_query_one, execute_update
            
            print(f"   üîç Looking for existing player: {tenniscores_player_id} in league {league_id}")
            
            # Try to get existing player
            result = execute_query_one(
                "SELECT id, tenniscores_player_id, first_name, last_name FROM players WHERE tenniscores_player_id = %s AND league_id = %s",
                [tenniscores_player_id, league_id]
            )
            
            if result:
                print(f"   ‚úÖ Found existing player: {result['id']} ({result['first_name']} {result['last_name']})")
                # Update existing player
                execute_update(
                    """
                    UPDATE players 
                    SET first_name = %s, last_name = %s, club_id = %s, series_id = %s, 
                        team_id = %s, pti = %s, wins = %s, losses = %s, 
                        win_percentage = %s, captain_status = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE id = %s
                    """,
                    [first_name, last_name, club_id, series_id, team_id, pti, wins, losses,
                     win_percentage, captain_status, result['id']]
                )
                print(f"   ‚úÖ Updated existing player")
                return result['id']
            else:
                print(f"   ‚ûï Creating new player: {first_name} {last_name}")
                # Insert new player
                result = execute_query_one(
                    """
                    INSERT INTO players (
                        tenniscores_player_id, first_name, last_name, league_id, club_id, 
                        series_id, team_id, pti, wins, losses, win_percentage, 
                        captain_status, is_active, created_at, updated_at
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, true, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                    RETURNING id
                    """,
                    [tenniscores_player_id, first_name, last_name, league_id, club_id,
                     series_id, team_id, pti, wins, losses, win_percentage, captain_status]
                )
                
                if result:
                    print(f"   ‚úÖ Created new player with ID: {result['id']}")
                    return result['id']
                else:
                    print(f"   ‚ùå Failed to create player")
                    return None
                
        except Exception as e:
            print(f"   ‚ùå Error upserting player: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def save_player_data(self, league_subdomain: str, first_name: str, last_name: str, club: str, series: str, player_data: Dict = None) -> Dict[str, Any]:
        """Save player data to JSON and database after confirmation"""
        try:
            print(f"üíæ Saving player data for {first_name} {last_name}")
            print(f"   üìä Received player_data: {player_data}")
            
            # Use provided player_data if available, otherwise search for it
            if not player_data:
                print(f"   üîç No player_data provided, searching for player...")
                player_data = self.search_for_player(league_subdomain, first_name, last_name, club, series)
                if not player_data:
                    return {
                        "success": False,
                        "error": f"Could not find player {first_name} {last_name} in {club}, {series}"
                    }
            else:
                print(f"   ‚úÖ Using provided player_data")
            
            print(f"   üîç Checking if player exists in JSON...")
            # Check if player already exists in JSON
            json_check = self._check_player_exists_in_json(player_data, league_subdomain)
            print(f"   üìã JSON check result: {json_check}")
            if json_check.get('exists'):
                print(f"   ‚ö†Ô∏è  Player already exists in JSON, will update existing record")
                # Don't return error, continue to update the existing player
            
            print(f"   üîç Checking if player exists in database...")
            # Check if player already exists in database
            db_check = self._check_player_exists_in_database(player_data)
            print(f"   üìã Database check result: {db_check}")
            if db_check.get('exists'):
                print(f"   ‚ö†Ô∏è  Player already exists in database, will update existing record")
                # Don't return error, continue to update the existing player
            
            print(f"   üíæ Saving to JSON file...")
            # Save to JSON file
            json_result = self._save_to_json(player_data, league_subdomain)
            print(f"   üìã JSON save result: {json_result}")
            if not json_result.get('success'):
                return json_result
            
            print(f"   üíæ Importing to database...")
            # Import to database
            db_result = self._import_to_database(player_data, league_subdomain)
            print(f"   üìã Database import result: {db_result}")
            if not db_result.get('success'):
                return db_result
            
            # Determine if this was an update or new addition
            was_update = json_check.get('exists') or db_check.get('exists')
            action_text = "updated" if was_update else "added"
            
            print(f"‚úÖ Player {first_name} {last_name} successfully {action_text} in both JSON and database")
            
            return {
                "success": True,
                "message": f"Player {first_name} {last_name} has been successfully {action_text} to the system!",
                "player_data": player_data,
                "json_result": json_result,
                "database_result": db_result,
                "was_update": was_update
            }
            
        except Exception as e:
            print(f"‚ùå Error saving player data: {e}")
            import traceback
            traceback.print_exc()
            self.cleanup_browser()
            return {"success": False, "error": str(e)}
    
    def _check_player_exists_in_json(self, player_data: Dict, league_subdomain: str) -> Dict[str, Any]:
        """Check if player already exists in JSON file"""
        try:
            from pathlib import Path
            import json
            
            # Convert league_subdomain to the correct directory name format
            if league_subdomain.lower() in ['aptachicago', 'apta']:
                league_dir_name = "APTA_CHICAGO"
            elif league_subdomain.lower() == 'cnswpl':
                league_dir_name = "CNSWPL"
            elif league_subdomain.lower() == 'nstf':
                league_dir_name = "NSTF"
            else:
                league_dir_name = league_subdomain.upper()
            
            league_dir = Path(f"data/leagues/{league_dir_name}")
            players_file = league_dir / "players.json"
            
            if not players_file.exists():
                return {"exists": False}
            
            with open(players_file, 'r') as f:
                existing_players = json.load(f)
            
            # Check by Player ID first (most reliable)
            for existing_player in existing_players:
                if existing_player.get('Player ID') == player_data['Player ID']:
                    return {
                        "exists": True,
                        "player_id": existing_player['Player ID'],
                        "location": "JSON file"
                    }
            
            # Check by name + club + series combination
            for existing_player in existing_players:
                if (existing_player.get('First Name', '').lower() == player_data['First Name'].lower() and
                    existing_player.get('Last Name', '').lower() == player_data['Last Name'].lower() and
                    existing_player.get('Club', '').lower() == player_data['Club'].lower() and
                    existing_player.get('Series', '').lower() == player_data['Series'].lower()):
                    return {
                        "exists": True,
                        "player_id": existing_player.get('Player ID', 'Unknown'),
                        "location": "JSON file (name+club+series match)"
                    }
            
            return {"exists": False}
            
        except Exception as e:
            print(f"Error checking JSON for duplicates: {e}")
            return {"exists": False}
    
    def _check_player_exists_in_database(self, player_data: Dict) -> Dict[str, Any]:
        """Check if player already exists in database"""
        try:
            # Import here to avoid circular imports
            from database_utils import execute_query_one
            
            # Check by tenniscores_player_id first (most reliable)
            result = execute_query_one(
                "SELECT id, tenniscores_player_id, first_name, last_name FROM players WHERE tenniscores_player_id = %s",
                [player_data['Player ID']]
            )
            
            if result:
                return {
                    "exists": True,
                    "player_id": result['id'],
                    "tenniscores_player_id": result['tenniscores_player_id'],
                    "location": "database (ID match)"
                }
            
            # Check by name + league combination
            # First get the league ID from the league name
            league_result = execute_query_one(
                "SELECT id FROM leagues WHERE league_id = %s OR league_name ILIKE %s",
                [player_data['League'], f"%{player_data['League']}%"]
            )
            
            if league_result:
                league_id = league_result['id']
                result = execute_query_one(
                    """
                    SELECT p.id, p.tenniscores_player_id, p.first_name, p.last_name, l.league_id
                    FROM players p
                    JOIN leagues l ON p.league_id = l.id
                    WHERE p.first_name = %s AND p.last_name = %s AND l.id = %s
                    """,
                    [player_data['First Name'], player_data['Last Name'], league_id]
                )
            else:
                result = None
            
            if result:
                return {
                    "exists": True,
                    "player_id": result['id'],
                    "tenniscores_player_id": result['tenniscores_player_id'],
                    "location": "database (name+league match)"
                }
            
            return {"exists": False}
            
        except Exception as e:
            print(f"Error checking database for duplicates: {e}")
            return {"exists": False}
